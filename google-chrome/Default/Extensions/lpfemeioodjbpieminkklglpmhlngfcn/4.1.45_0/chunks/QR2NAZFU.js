import{a as ne,c as K}from"./IPPTDVLS.js";import{a as Z,b as U,e as J,g as G}from"./EVSA3OY5.js";import{a as $,b as C,c as M,d as F,e as H}from"./C2E66DLF.js";import"./SSXGEXEV.js";import{f as te}from"./3PS7M655.js";var j=te(ne(),1);var x=class extends G{constructor(e){super(e)}async generate(e,t,n){var b;let r=[],a=[],s;Array.isArray(t)?s={stop:t}:t!=null&&t.timeout&&!t.signal?s={...t,signal:AbortSignal.timeout(t.timeout)}:s=t!=null?t:{};let h=await J.configure(n,this.callbacks,{verbose:this.verbose}),y={invocation_params:this==null?void 0:this.invocationParams()},o=await(h==null?void 0:h.handleChatModelStart({name:this._llmType()},e,void 0,void 0,y));try{let l=await Promise.all(e.map(m=>this._generate(m,s,o)));for(let m of l)m.llmOutput&&a.push(m.llmOutput),r.push(m.generations)}catch(l){throw await(o==null?void 0:o.handleLLMError(l)),l}let i={generations:r,llmOutput:a.length?(b=this._combineLLMOutput)==null?void 0:b.call(this,...a):void 0};return await(o==null?void 0:o.handleLLMEnd(i)),Object.defineProperty(i,$,{value:o?{runId:o==null?void 0:o.runId}:void 0,configurable:!0}),i}invocationParams(){return{}}_modelType(){return"base_chat_model"}async generatePrompt(e,t,n){let r=e.map(a=>a.toChatMessages());return this.generate(r,t,n)}async call(e,t,n){return(await this.generate([e],t,n)).generations[0][0].message}async callPrompt(e,t,n){let r=e.toChatMessages();return this.call(r,t,n)}async predictMessages(e,t,n){return this.call(e,t,n)}async predict(e,t,n){let r=new C(e);return(await this.call([r],t,n)).text}};function Q(g){switch(g){case"system":return"system";case"ai":return"assistant";case"human":return"user";default:throw new Error(`Unknown message type: ${g}`)}}function re(g,e){switch(g){case"user":return new C(e);case"assistant":return new M(e);case"system":return new F(e);default:return new H(e,g!=null?g:"unknown")}}var X=class extends x{get callKeys(){return["stop","signal","timeout","options"]}constructor(e,t){var y,o,i,b,l,m,d,I,f,k,v,_,N,u,P,c,T,A;super(e!=null?e:{}),Object.defineProperty(this,"temperature",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"topP",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"frequencyPenalty",{enumerable:!0,configurable:!0,writable:!0,value:0}),Object.defineProperty(this,"presencePenalty",{enumerable:!0,configurable:!0,writable:!0,value:0}),Object.defineProperty(this,"n",{enumerable:!0,configurable:!0,writable:!0,value:1}),Object.defineProperty(this,"logitBias",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"modelName",{enumerable:!0,configurable:!0,writable:!0,value:"gpt-3.5-turbo"}),Object.defineProperty(this,"modelKwargs",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"stop",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"timeout",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"streaming",{enumerable:!0,configurable:!0,writable:!0,value:!1}),Object.defineProperty(this,"maxTokens",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"azureOpenAIApiVersion",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"azureOpenAIApiKey",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"azureOpenAIApiInstanceName",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"azureOpenAIApiDeploymentName",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"client",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"clientConfig",{enumerable:!0,configurable:!0,writable:!0,value:void 0});let n=(o=e==null?void 0:e.openAIApiKey)!=null?o:typeof process!="undefined"?(y=process.env)==null?void 0:y.OPENAI_API_KEY:void 0,r=(b=e==null?void 0:e.azureOpenAIApiKey)!=null?b:typeof process!="undefined"?(i=process.env)==null?void 0:i.AZURE_OPENAI_API_KEY:void 0;if(!r&&!n)throw new Error("(Azure) OpenAI API key not found");let a=(m=e==null?void 0:e.azureOpenAIApiInstanceName)!=null?m:typeof process!="undefined"?(l=process.env)==null?void 0:l.AZURE_OPENAI_API_INSTANCE_NAME:void 0,s=(I=e==null?void 0:e.azureOpenAIApiDeploymentName)!=null?I:typeof process!="undefined"?(d=process.env)==null?void 0:d.AZURE_OPENAI_API_DEPLOYMENT_NAME:void 0,h=(k=e==null?void 0:e.azureOpenAIApiVersion)!=null?k:typeof process!="undefined"?(f=process.env)==null?void 0:f.AZURE_OPENAI_API_VERSION:void 0;if(this.modelName=(v=e==null?void 0:e.modelName)!=null?v:this.modelName,this.modelKwargs=(_=e==null?void 0:e.modelKwargs)!=null?_:{},this.timeout=e==null?void 0:e.timeout,this.temperature=(N=e==null?void 0:e.temperature)!=null?N:this.temperature,this.topP=(u=e==null?void 0:e.topP)!=null?u:this.topP,this.frequencyPenalty=(P=e==null?void 0:e.frequencyPenalty)!=null?P:this.frequencyPenalty,this.presencePenalty=(c=e==null?void 0:e.presencePenalty)!=null?c:this.presencePenalty,this.maxTokens=e==null?void 0:e.maxTokens,this.n=(T=e==null?void 0:e.n)!=null?T:this.n,this.logitBias=e==null?void 0:e.logitBias,this.stop=e==null?void 0:e.stop,this.streaming=(A=e==null?void 0:e.streaming)!=null?A:!1,this.azureOpenAIApiVersion=h,this.azureOpenAIApiKey=r,this.azureOpenAIApiInstanceName=a,this.azureOpenAIApiDeploymentName=s,this.streaming&&this.n>1)throw new Error("Cannot stream results when n > 1");if(this.azureOpenAIApiKey){if(!this.azureOpenAIApiInstanceName)throw new Error("Azure OpenAI API instance name not found");if(!this.azureOpenAIApiDeploymentName)throw new Error("Azure OpenAI API deployment name not found");if(!this.azureOpenAIApiVersion)throw new Error("Azure OpenAI API version not found")}this.clientConfig={apiKey:n,...t}}invocationParams(){return{model:this.modelName,temperature:this.temperature,top_p:this.topP,frequency_penalty:this.frequencyPenalty,presence_penalty:this.presencePenalty,max_tokens:this.maxTokens===-1?void 0:this.maxTokens,n:this.n,logit_bias:this.logitBias,stop:this.stop,stream:this.streaming,...this.modelKwargs}}_identifyingParams(){return{model_name:this.modelName,...this.invocationParams(),...this.clientConfig}}identifyingParams(){return this._identifyingParams()}async _generate(e,t,n){var l,m,d,I,f,k,v,_,N;let r={};if(this.stop&&(t!=null&&t.stop))throw new Error("Stop found in input and default params");let a=this.invocationParams();a.stop=(l=t==null?void 0:t.stop)!=null?l:a.stop;let s=e.map(u=>({role:Q(u._getType()),content:u.text,name:u.name})),h=a.stream?await new Promise((u,P)=>{let c,T=!1,A=!1;this.completionWithRetry({...a,messages:s},{signal:t==null?void 0:t.signal,...t==null?void 0:t.options,adapter:K,responseType:"stream",onmessage:z=>{var E,L,R,D,V,q,S,B,W,Y;if(((L=(E=z.data)==null?void 0:E.trim)==null?void 0:L.call(E))==="[DONE]"){if(A)return;A=!0,u(c)}else{let w=JSON.parse(z.data);c||(c={id:w.id,object:w.object,created:w.created,model:w.model,choices:[]});for(let p of w.choices)if(p!=null){let O=c.choices.find(ee=>ee.index===p.index);O||(O={index:p.index,finish_reason:(R=p.finish_reason)!=null?R:void 0},c.choices[p.index]=O),O.message||(O.message={role:(D=p.delta)==null?void 0:D.role,content:(q=(V=p.delta)==null?void 0:V.content)!=null?q:""}),O.message.content+=(B=(S=p.delta)==null?void 0:S.content)!=null?B:"",n==null||n.handleLLMNewToken((Y=(W=p.delta)==null?void 0:W.content)!=null?Y:"")}!A&&w.choices.every(p=>p.finish_reason!=null)&&(A=!0,u(c))}}}).catch(z=>{T||(T=!0,P(z))})}):await this.completionWithRetry({...a,messages:s},{signal:t==null?void 0:t.signal,...t==null?void 0:t.options}),{completion_tokens:y,prompt_tokens:o,total_tokens:i}=(m=h.usage)!=null?m:{};y&&(r.completionTokens=((d=r.completionTokens)!=null?d:0)+y),o&&(r.promptTokens=((I=r.promptTokens)!=null?I:0)+o),i&&(r.totalTokens=((f=r.totalTokens)!=null?f:0)+i);let b=[];for(let u of h.choices){let P=(v=(k=u.message)==null?void 0:k.role)!=null?v:void 0,c=(N=(_=u.message)==null?void 0:_.content)!=null?N:"";b.push({text:c,message:re(P,c)})}return{generations:b,llmOutput:{tokenUsage:r}}}async getNumTokensFromMessages(e){let t=0,n=0,r=0;U(this.modelName)==="gpt-3.5-turbo"?(n=4,r=-1):U(this.modelName).startsWith("gpt-4")&&(n=3,r=1);let a=await Promise.all(e.map(async s=>{let h=await this.getNumTokens(s.text),y=await this.getNumTokens(Q(s._getType())),o=s.name!==void 0?r+await this.getNumTokens(s.name):0,i=h+n+y+o;return t+=i,i}));return t+=3,{totalCount:t,countPerMessage:a}}async completionWithRetry(e,t){if(!this.client){let r=this.azureOpenAIApiKey?`https://${this.azureOpenAIApiInstanceName}.openai.azure.com/openai/deployments/${this.azureOpenAIApiDeploymentName}`:this.clientConfig.basePath,a=new j.Configuration({...this.clientConfig,basePath:r,baseOptions:{timeout:this.timeout,...this.clientConfig.baseOptions}});this.client=new j.OpenAIApi(a)}let n={adapter:Z()?void 0:K,...this.clientConfig.baseOptions,...t};return this.azureOpenAIApiKey&&(n.headers={"api-key":this.azureOpenAIApiKey,...n.headers},n.params={"api-version":this.azureOpenAIApiVersion,...n.params}),this.caller.call(this.client.createChatCompletion.bind(this.client),e,n).then(r=>r.data)}_llmType(){return"openai"}_combineLLMOutput(...e){return e.reduce((t,n)=>{var r,a,s;return n&&n.tokenUsage&&(t.tokenUsage.completionTokens+=(r=n.tokenUsage.completionTokens)!=null?r:0,t.tokenUsage.promptTokens+=(a=n.tokenUsage.promptTokens)!=null?a:0,t.tokenUsage.totalTokens+=(s=n.tokenUsage.totalTokens)!=null?s:0),t},{tokenUsage:{completionTokens:0,promptTokens:0,totalTokens:0}})}};export{X as ChatOpenAI};
